{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jolin-io/KI2022-tutorial-universal-differential-equations/main?filepath=04%20introduction%20to%20bayesian%20differential%20equations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.jolin.io\" target=\"_blank\" rel=\"noreferrer noopener\">\n",
    "<img src=\"https://www.jolin.io/assets/Jolin/Jolin-Banner-Website-v1.1-darkmode.webp\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to bayesian differential equations in <img height=\"60px\" style='height:60px;display:inline;' alt=\"Julia\" src=\"https://julialang.org/assets/infra/logo.svg\">\n",
    "\n",
    "There are several well-known probabilistic programming packages for julia, all written in pure julia:\n",
    "- [Turing.jl](https://github.com/TuringLang/Turing.jl) for bayesian inference\n",
    "- [Gen.jl](https://github.com/probcomp/Gen.jl) with programmable inference\n",
    "- [Soss.jl](https://github.com/cscherrer/Soss.jl)\n",
    "- and many more\n",
    "\n",
    "We use Turing, because it comes with the very good support for UDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Turing, Distributions, Random, Statistics, StatsBase, StatsPlots\n",
    "import DifferentialEquations, Plots, LinearAlgebra\n",
    "using CommonSolve: solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turing.jl - Uncertainty Modelling via Bayesian Estimation\n",
    "\n",
    "Let's get into Turing.jl via an example: The Coin Flip mini example.\n",
    "\n",
    "find more details at https://turing.ml/dev/tutorials/00-introduction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the true probability of heads in a coin.\n",
    "p_true = 0.5\n",
    "\n",
    "# Iterate from having seen 0 observations to 100 observations.\n",
    "N = 100\n",
    "\n",
    "# Draw data from a Bernoulli distribution, i.e. draw heads or tails.\n",
    "Random.seed!(12)\n",
    "data = Random.rand(Distributions.Bernoulli(p_true), N)\n",
    "\n",
    "# Declare our Turing model.\n",
    "Turing.@model function coinflip(y)\n",
    "    # Our prior belief about the probability of heads in a coin.\n",
    "    p ~ Distributions.Beta(1, 1)\n",
    "\n",
    "    # The number of observations.\n",
    "    yN = length(y)\n",
    "    for n in 1:yN\n",
    "        # Heads or tails of a coin are drawn from a Bernoulli distribution.\n",
    "        y[n] ~ Distributions.Bernoulli(p)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Settings of the Hamiltonian Monte Carlo (HMC) sampler.\n",
    "iterations = 1000\n",
    "Ïµ = 0.05\n",
    "Ï„ = 10\n",
    "\n",
    "# Start sampling.\n",
    "chain = StatsBase.sample(coinflip(data), Turing.HMC(Ïµ, Ï„), iterations)\n",
    "Plots.plot(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.histogram(chain[:p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ‘‰ It is your time:** Try different `N` above and see how our information about `p` improves/worsens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Differential Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume noisy Lotka Volterra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lotka_volterra(du, u, p, t)\n",
    "    x, y = u\n",
    "    Î±, Î², Î´, Î³ = p\n",
    "    du[1] = dx = Î±*x - Î²*x*y\n",
    "    du[2] = dy = -Î´*y + Î³*x*y\n",
    "end\n",
    "u0 = [1.0, 1.0]\n",
    "tspan = (0.0, 10.0)\n",
    "p = [1.5, 1.0, 3.0, 1.0]\n",
    "ode_prob = DifferentialEquations.ODEProblem(lotka_volterra, u0, tspan, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode_sol = solve(ode_prob, saveat=0.1)\n",
    "ode_data = (Array(ode_sol) + 0.8\n",
    "           * Random.randn(size(Array(ode_sol))))\n",
    "# Plot simulation & noisy observations\n",
    "Plots.plot(ode_sol, alpha=0.3)\n",
    "Plots.scatter!(ode_sol.t, ode_data', color=[1 2], label=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we only have predator-data (foxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Turing.@model function fitlv(data::AbstractVector, ode_prob)\n",
    "    # Prior distributions.\n",
    "    Î± ~ Distributions.truncated(Distributions.Normal(1.5, 0.5), 0.5, 2.5)\n",
    "    Î² ~ Distributions.truncated(Distributions.Normal(1.2, 0.5), 0, 2)\n",
    "    Î³ ~ Distributions.truncated(Distributions.Normal(3.0, 0.5), 1, 4)\n",
    "    Î´ ~ Distributions.truncated(Distributions.Normal(1.0, 0.5), 0, 2)\n",
    "    p = [Î±, Î², Î³, Î´]\n",
    "    \n",
    "    # Simulate Lotka-Volterra model but save only\n",
    "    # the second state of the system (predators).\n",
    "    predicted = solve(ode_prob, p=p, saveat=0.1, save_idxs=2)\n",
    "    \n",
    "    # Observations of the predators.\n",
    "    Ïƒ ~ Distributions.InverseGamma(2, 3)\n",
    "    data ~ Distributions.MvNormal(predicted.u, Ïƒ^2 * LinearAlgebra.I)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "# fit model only to predators (foxes)\n",
    "model = fitlv(ode_data[2, :], ode_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample & plot (called data retroduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sample 3 independent chains.\n",
    "chain = StatsBase.sample(model, Turing.NUTS(0.45), Turing.MCMCSerial(), 5000, 3, progress=false)\n",
    "posterior_samples = StatsBase.sample(chain[[:Î±, :Î², :Î³, :Î´]], 300, replace=false)\n",
    "\n",
    "Plots.plot(legend=false)\n",
    "for p in eachrow(Array(posterior_samples))\n",
    "    ode_sol_p = solve(ode_prob, p=p, saveat=0.1)\n",
    "    Plots.plot!(ode_sol_p, alpha=0.1, color=\"#BBBBBB\")\n",
    "end\n",
    "\n",
    "# Plot simulation and noisy observations.\n",
    "Plots.plot!(ode_sol, color=[1 2], linewidth=1)\n",
    "Plots.scatter!(ode_sol.t, ode_data', color=[1 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ‘‰ It is your time:** How can we check whether the MCMC Bayesian Estimation converged successfully?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That was the introduction to bayesian differential equations - Thank you for participating ðŸ™‚\n",
    "\n",
    "If you have question, suggestions, or you are just interested in Julia, contact me:\n",
    "- Stephan Sahm stephan.sahm@jolin.io\n",
    "\n",
    "### Further Material\n",
    "\n",
    "- [Tutorial Bayesian Differential Equations](https://turing.ml/dev/tutorials/10-bayesian-differential-equations/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.jolin.io\" target=\"_blank\" rel=\"noreferrer noopener\">\n",
    "<img src=\"https://www.jolin.io/assets/Jolin/Jolin-Banner-Website-v1.1-darkmode.webp\">\n",
    "</a>\n",
    "\n",
    "#### Supported by [Jolin.io](https://www.jolin.io)\n",
    "\n",
    "Jolin.io is an IT-consultancy for high-performance computing and data science\n",
    "\n",
    "We are there to help you, if you want to\n",
    "- try out Julia at your company, or\n",
    "- transition Matlab, Fortran, R, Python, etc. to Julia\n",
    "- or speed up your existing code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
